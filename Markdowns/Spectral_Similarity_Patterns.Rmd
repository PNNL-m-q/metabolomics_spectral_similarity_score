---
title: "Spectral_Similarity_Patterns"
author: "Degnan, David J"
date: "2023-06-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE)
library(data.table)
library(dplyr)
library(tidyr)
library(pheatmap)
library(ggplot2)
library(patchwork)
library(DT)
library(rsample)
library(randomForest)
library(recipes)
```

## Read all files 

```{r Create Max and Sum datasets}
# Load CoreMS Directory 
#CoreMS_Dir <- "/Users/degn400/Library/Group Containers/UBF8T346G9.OneDriveStandaloneSuite/OneDrive - PNNL.noindex/OneDrive - #PNNL/Desktop/MQ/MQ_Data/Final_Dataset"
#
## List files 
#MaxFiles <- list.files(file.path(CoreMS_Dir, "MAX"), full.names = T)
#SumFiles <- list.files(file.path(CoreMS_Dir, "SUM"), full.names = T)
#
## Function to extract data 
#pullData <- function(files) {
#  
#  return(do.call(bind_rows, lapply(files, function(x) {
#    
#    message(x)
#    
#    data <- fread(x) %>% 
#      dplyr::select(-c(`Retention Time`, `Retention Time Ref`, `Retention index`, `Retention index Ref`, `Retention Index Score`, Reason)) 
#    
#    numOmitted <- rowSums(is.na(data)) %>% .[. > 0] %>% length()
#    totalNum <- nrow(data)
#    
#    message(paste0("...Number omitted: ", numOmitted, " out of the total: ", totalNum, " which is ", round(numOmitted / totalNum, 4) * 100, "%"))
#    
#    data <- data %>% na.omit()
#    
#    # Random type fixes since data science the output is in scientific notation that 
#    # is sometimes read as a string. 
#    data$`Vicis Wave Hadges Distance` <- as.numeric(data$`Vicis Wave Hadges Distance`)
#    data$VW1 <- as.numeric(data$VW1)
#    data$`Symmetric Chi Squared Distance` <- as.numeric(data$`Symmetric Chi Squared Distance`)
#    data$`Kumar Johnson Distance` <- as.numeric(data$`Kumar Johnson Distance`)
#    data$`Kumar Johnson Divergence` <- as.numeric(data$`Kumar Johnson Divergence`)
#    
#    return(data)
#    
#  })))
#
#}
#
#MaxData <- pullData(MaxFiles)
#SumData <- pullData(SumFiles)
#
#fwrite(MaxData, "~/Downloads/MaxData.tsv", quote = F, row.names = F, sep = "\t")
#fwrite(SumData, "~/Downloads/SumData.tsv", quote = F, row.names = F, sep = "\t")
```

## Correlation Score

#### Pearson Correlation: Max Score

```{r, MaxPearson, fig.height = 12, fig.width = 12}
MaxPearson <- fread("../Data/Max_Pearson.txt")
MP_Mat <- matrix(MaxPearson$Pearson, nrow = 74, ncol = 74)
colnames(MP_Mat) <- row.names(MP_Mat) <- MaxPearson$Score1 %>% unique()

HMA <- pheatmap(MP_Mat, main = "Max: Pearson Correlation")
HMA
```

#### Pearson Correlation: Sum Score

```{r, SumPearson, fig.height = 12, fig.width = 12}
SumPearson <- fread("../Data/Sum_Pearson.txt")
SP_Mat <- matrix(SumPearson$Pearson, nrow = 74, ncol = 74)
colnames(SP_Mat) <- row.names(SP_Mat) <- MaxPearson$Score1 %>% unique()

HMB <- pheatmap(SP_Mat, main = "Sum: Pearson Correlation")
HMB
```

## Add T Statistic & Distributional Properties

Here, we are only interested in a t-statistic to measure the separation of score
distributions between true positives and true negatives. 

```{r}
## Add distribution properties 
#Sum <- fread("~/Downloads/SumData.tsv")
#
#SummaryStats <- do.call(bind_rows, lapply(ScoreMetadata$Score, function(x) {
#  c(
#    Score = x,
#    Sum_ScoreMin = Sum[[x]] %>% as.numeric() %>% min() %>% round(4),
#    Sum_ScoreMedian = Sum[[x]] %>% as.numeric() %>% median() %>% round(4),
#    Sum_ScoreMax = Sum[[x]] %>% as.numeric() %>% max() %>% round(4),
#    Max_ScoreMin = Max[[x]] %>% as.numeric() %>% min() %>% round(4),
#    Max_ScoreMedian = Max[[x]] %>% as.numeric() %>% median() %>% round(4),
#    Max_ScoreMax = Max[[x]] %>% as.numeric() %>% max() %>% round(4)
#  )
#}))
#ScoreMetadata <- ScoreMetadata %>% merge(SummaryStats, by = "Score")

## T-Statistics for Sum
#TstatsSum <- lapply(ScoreMetadata$Score, function(theScore) {
#  
#  # Extract the score sample
#  ScoreSample <- Sum %>% 
#    dplyr::select(!!theScore, Truth.Annotation) %>% 
#    dplyr::filter(Truth.Annotation != "")
#  
#  return(
#    t.test(
#      x = unlist(ScoreSample[ScoreSample$Truth.Annotation == "True.Positive", 1]) %>% as.numeric(),
#      y = unlist(ScoreSample[ScoreSample$Truth.Annotation == "True.Negative", 1]) %>% as.numeric(),
#      alternative = "two.sided"
#    )$statistic
#  )
#  
#}) %>% unlist()
#
## T-Statistics for Max
#TstatsMax <- lapply(ScoreMetadata$Score, function(theScore) {
#  
#  # Extract the score sample
#  ScoreSample <- Max %>% 
#    dplyr::select(!!theScore, Truth.Annotation) %>% 
#    dplyr::filter(Truth.Annotation != "")
#  
#  return(
#    t.test(
#      x = unlist(ScoreSample[ScoreSample$Truth.Annotation == "True.Positive", 1]) %>% as.numeric(),
#      y = unlist(ScoreSample[ScoreSample$Truth.Annotation == "True.Negative", 1]) %>% as.numeric(),
#      alternative = "two.sided"
#    )$statistic
#  )
#  
#}) %>% unlist()
#
#ScoreMetadata$TStatisticSum <- TstatsSum
#ScoreMetadata$TStatisticMax <- TstatsMax

ScoreMetadata <- fread("../Metadata/Score_Metadata.txt")

datatable(ScoreMetadata, options = list(scrollX = TRUE))
```

Descriptions: 

**Score:** The tested spectral similarity score

**Family:** The family of metrics the score comes from 

**Type:** Indicates whether the score is a similarity (ranges from 0-1 or -1 to 1 
fore directionality) or a distance (typically unbounded on one or both sides)

**Theoretical Bounds:** The bounds written as a categorical variable 

**Theoretical Bounds 2:** The bounds written in bracket format where a square bracket
is inclusive and a parentheses is not inclusive. 

**SumCluster:** The cluster number the score falls into for the sum data 

**MaxCluster:** The cluster number the score falls into for the max data 

**Sum_ScoreMin:** The score's minimum value in the sum dataset

**Sum_ScoreMedian:** The score's median value in the sum dataset

**Sum_ScoreMax:** The score's maximum value in the sum dataset 

**Max_ScoreMin:** The score's minimum value in the max dataset

**Max_ScoreMedian:** The score's median value in the max dataset

**Max_ScoreMax:** The score's maximum value in the max dataset 

**TStatisticSum:** The t-statistic between the true positives and true negatives
for a score in the sum data 

**TStatisticMax:** The t-statistic between the true positives and true negatives 
for a score in the max data 

## Random Forest 

Data was split into 75% training and 25% testing datasets. Hyperparameters were 
fine tuned using the recipes and workflowsets R packages with leave one out 10-fold 
cross-validation repeated 5 times each for a total of 50 times. Random forest
models were fit using the ranger R package. 

#### Sum Model

The best fit model was: 

```{r}
SumModel <- readRDS("../Data/Sum_RF_Results.RDS")
SumModel[[1]]
```

The testing dataset yielded the following results: 

```{r}
SumModel[[2]]
```

Description:

```{r}
SumModel[[3]]
```

Description:

```{r}
SumModel[[4]]
```

#### Max Model

The best fit model was: 

```{r}
MaxModel <- readRDS("../Data/Max_RF_Results.RDS")
MaxModel[[1]]
```

The testing dataset yielded the following results: 

```{r}
MaxModel[[2]]
```

Description:

```{r}
MaxModel[[3]]
```

Description:

```{r}
MaxModel[[4]]
```

## Cluster Description


